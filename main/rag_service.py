import os
import asyncio
import threading
from typing import Optional

from django.conf import settings

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã®è¨­å®š
os.environ["LANGCHAIN_TRACING_V2"] = "false"
os.environ["LANGCHAIN_CALLBACKS_MANAGER"] = "disabled"

from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


_rag_lock = threading.Lock()
_rag_ready = False
_rag_chain = None


def _default_vector_store_path() -> str:
    # settings.pyã‹ã‚‰ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ãƒ‘ã‚¹ã‚’å–å¾—
    vector_store_path = getattr(settings, "VECTOR_STORE_PATH", None)
    if not vector_store_path:
        raise ValueError("VECTOR_STORE_PATHãŒsettings.pyã§è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    return str(vector_store_path)


def _build_rag_chain():
    google_api_key = getattr(settings, "GOOGLE_API_KEY", None)
    if not google_api_key:
        raise RuntimeError("GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    vector_store_path = _default_vector_store_path()

    print(f"ğŸ” ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‘ã‚¹ç¢ºèª: {vector_store_path}")
    if not os.path.exists(vector_store_path):
        raise FileNotFoundError(f"ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vector_store_path}")

    # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’è¨­å®šï¼ˆåˆæœŸåŒ–æ™‚ã®ã¿ï¼‰
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    # Embeddings ã¨ VectorStore ã‚’åˆæœŸåŒ–
    print("ğŸ“¥ Embeddingsãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=google_api_key)

    print("ğŸ“‚ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢èª­ã¿è¾¼ã¿ä¸­...")
    vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)

    base_retriever = vector_store.as_retriever(
        search_type="similarity_score_threshold", search_kwargs={"k": 16, "score_threshold": 0.1}
    )

    print("ğŸ¤– LLMãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite",
        google_api_key=google_api_key,
        temperature=0,
        max_retries=1,
        timeout=60,
    )

    prompt_template = (
        """
ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ã€Œå‚è€ƒæƒ…å ±ã€ã‚’ä¸»ã«ç”¨ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè³ªå•ã€ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€æŒ™ã’ã‚‹ä½œå“ã¯ã§ãã‚‹é™ã‚Šå°èª¬ã§ç‹‚è¨€ã‚„èƒ½ã¯é¿ã‘ã‚‹ã‚ˆã†ã«ã—ã€1ã¤ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ä»¥ä¸‹ã«æº–æ‹ ã—ã¦ãã ã•ã„ã€‚
ãŸã ã—ã€å…·ä½“çš„ãªä½œè€…ã‚’æŒ‡å®šã•ã‚Œãªã„å ´åˆã€ä½œå“ãŒèª°ã‚‚ãŒèª­ã‚“ã ã“ã¨ã®ã‚ã‚‹ã‚ˆã†ãªä½œå“ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ã‚’é¿ã‘ã¦ãã ã•ã„ã€‚
å‚è€ƒæƒ…å ±ãŒä¸ååˆ†ãªå ´åˆã¯ã€æ¤œç´¢ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æƒ…å ±ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒé’ç©ºæ–‡åº«ã®ä¸­ã‹ã‚‰å…·ä½“çš„ãªä½œå“æƒ…å ±ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚å›ç­”ã¯ç°¡æ½”ã«ã€å¯èƒ½ãªã‚‰ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚æœ€å¾Œã«å‚è€ƒã«ã—ãŸä½œå“åï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ»ä½œè€…ï¼‰ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚


ã€å‚è€ƒæƒ…å ±ã€‘
{context}

ã€è³ªå•ã€‘
{question}

ã€å›ç­”ã€‘
"""
    )
    prompt = ChatPromptTemplate.from_template(prompt_template)

    print("ğŸ” Retrieverè¨­å®šå®Œäº†")

    def format_docs(docs):
        lines = []
        for i, d in enumerate(docs, 1):
            md = getattr(d, "metadata", {}) or {}
            title = md.get("title", "ä¸æ˜")
            author = md.get("author", "ä¸æ˜")
            source = md.get("source", "")
            lines.append(f"[{i}] ã‚¿ã‚¤ãƒˆãƒ«: {title}ï¼ˆ{author}ï¼‰\nå‡ºå…¸: {source}\næœ¬æ–‡æŠœç²‹:\n{getattr(d, 'page_content', '')}")
        return "\n\n---\n\n".join(lines)

    def filter_docs(docs):
        filtered = []
        for d in docs:
            text = (getattr(d, "page_content", "") or "").strip()
            if len(text) < 60:
                continue
            if sum(ch.isdigit() for ch in text) > max(1, int(len(text) * 0.4)):
                continue
            filtered.append(d)
        return filtered or docs

    QUERY_KEYWORDS = [
        "æ˜¥", "æ˜¥é¢¨", "æ˜¥é›¨", "æ˜¥å®µ", "æœ§æœˆå¤œ", "è‹¥è‘‰", "æ–°ç·‘", "èŠ±è¦‹", "æ¡œ", "æ¢…", "èœã®èŠ±", "ã¤ã¤ã˜", "è—¤", "ã†ãã„ã™",
        "å¤", "çœŸå¤", "ç››å¤", "å¤è‡³", "å¤•æš®ã‚Œ", "å¤•æ–¹", "é»„æ˜", "å¤•ç„¼ã‘", "å¤•ç«‹", "ç´æ¶¼", "æ‰“ã¡æ°´", "æš‘æ°—æ‰•ã„",
        "è‰", "ã›ã¿", "è›", "ã»ãŸã‚‹", "é‡‘é­š", "å…¥é“é›²", "æœé¡”", "å‘æ—¥è‘µ", "ã²ã¾ã‚ã‚Š", "ãƒ©ãƒ ãƒ", "æ°·æ°´",
        "æµ·", "æ¸š", "ç ‚æµœ", "æ½®é¢¨", "æµœè¾º", "ç¸æ—¥", "ç¥­", "æµ´è¡£", "å›£æ‰‡", "ã†ã¡ã‚", "æ‰‡å­", "èŠ±ç«", "ç›†", "ç›†è¸Šã‚Š",
        "ç§‹", "ç§‹é›¨", "ç§‹é¢¨", "é‡åˆ†", "å¤œé•·", "å½¼å²¸", "å½¼å²¸èŠ±", "æ›¼ç æ²™è¯", "æœˆ", "åæœˆ", "ä¸­ç§‹", "æœˆè¦‹",
        "ç´…è‘‰", "é»„è‘‰", "ç¨²ç©‚", "æ–°ç±³", "ã™ã™ã", "è™«ã®éŸ³", "éˆ´è™«", "æ¾è™«", "ãã‚Šãã‚Šã™", "éŠ€æ",
        "å†¬", "çœŸå†¬", "æœ¨æ¯ã—", "åŒ—é¢¨", "éœœ", "éœœå¤œ", "é›ª", "ç²‰é›ª", "åˆé›ª", "å¹é›ª", "æ°·", "å‡ã¦ã¤ã",
        "ç‚¬ç‡µ", "ã“ãŸã¤", "ç«é‰¢", "ç‚­ç«", "å›²ç‚‰è£", "ã¿ã‹ã‚“", "é›ªæ˜ã‚Š", "å¸«èµ°", "å¹´ã®ç€¬",
        "é›¨", "å°é›¨", "é©Ÿé›¨", "ã«ã‚ã‹é›¨", "éœ§", "éœ", "é›²", "æ›‡", "å¿«æ™´", "æ™´å¤©", "é›·", "ç¨²å¦»", "è™¹",
        "é¢¨", "æ¶¼é¢¨", "å¯’é¢¨", "å—é¢¨", "åŒ—é¢¨",
        "æœ", "æœç„¼ã‘", "æ˜¼", "æ­£åˆ", "å¤•", "é€¢é­”ãŒæ™‚", "å®µ", "å®µé—‡", "å¤œ", "çœŸå¤œä¸­", "å¤œæ˜ã‘", "æš", "æ˜ã‘æ–¹",
    ]

    def extract_query_terms(question: str) -> set:
        terms = set()
        if not question:
            return terms
        for w in QUERY_KEYWORDS:
            if w in question:
                terms.add(w)
        return terms

    def rerank_docs(docs, question: str, top_n: int = 10):
        docs = filter_docs(docs)
        terms = extract_query_terms(question)
        if not terms:
            return docs[:top_n]

        filtered_by_terms = []
        for d in docs:
            text = getattr(d, "page_content", "")
            md = getattr(d, "metadata", {}) or {}
            kw = md.get("keywords") or {}
            hit = any(t in text for t in terms)
            if not hit and isinstance(kw, dict):
                for arr in kw.values():
                    if any(t in arr for t in terms):
                        hit = True
                        break
            if hit:
                filtered_by_terms.append(d)
        if filtered_by_terms:
            docs = filtered_by_terms

        def score(d):
            text = getattr(d, "page_content", "")
            s = 0
            for t in terms:
                s += text.count(t) * 2
            md = getattr(d, "metadata", {}) or {}
            kw = md.get("keywords", {}) or {}
            if isinstance(kw, dict):
                for arr in kw.values():
                    for t in terms:
                        if t in arr:
                            s += 3
            return s

        ranked = sorted(docs, key=score, reverse=True)
        return ranked[:top_n]

    print("âš™ï¸ RAGãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰ä¸­...")

    def rag_pipeline(question):
        docs = base_retriever.invoke(question)
        filtered_docs = rerank_docs(docs, question)
        context = format_docs(filtered_docs)
        messages = prompt.format_messages(context=context, question=question)
        response = llm.invoke(messages)
        return response.content

    print("âœ… RAGãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰å®Œäº†")
    return rag_pipeline


def ensure_rag_ready():
    global _rag_ready, _rag_chain
    if _rag_ready and _rag_chain is not None:
        return
    with _rag_lock:
        if not _rag_ready:
            print("ğŸš€ RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹...")
            try:
                # Google APIã‚­ãƒ¼ã®ç¢ºèª
                google_api_key = getattr(settings, "GOOGLE_API_KEY", None)
                if not google_api_key or not google_api_key.strip():
                    print("âš ï¸ GOOGLE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚RAGã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    _rag_chain = None
                    _rag_ready = True
                    return
                
                # Railwayç’°å¢ƒã§ã¯åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã®é‡ã„å‡¦ç†ã‚’é¿ã‘ã‚‹ï¼‰
                if os.environ.get('RAILWAY_ENVIRONMENT') and not os.environ.get('ENABLE_RAG_IN_RAILWAY'):
                    print("âš ï¸ Railwayç’°å¢ƒã§ã¯RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                    print("âš ï¸ æœ¬ç•ªç’°å¢ƒã§RAGã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ENABLE_RAG_IN_RAILWAYç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                    _rag_chain = None
                    _rag_ready = True
                    return
                
                _rag_chain = _build_rag_chain()
                _rag_ready = True
                print("âœ… RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                print(f"âŒ RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
                # åˆæœŸåŒ–å¤±æ•—æ™‚ã¯Noneã‚’è¨­å®šã—ã¦å¾Œã§å†è©¦è¡Œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
                _rag_chain = None
                _rag_ready = False
                print("âš ï¸ RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚å¾Œã§å†è©¦è¡Œã•ã‚Œã¾ã™ã€‚")


def _run_with_event_loop(func, *args, **kwargs):
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(_run_in_new_thread, func, *args, **kwargs)
                return future.result()
        else:
            return func(*args, **kwargs)
    except RuntimeError:
        return _run_in_new_thread(func, *args, **kwargs)


def _run_in_new_thread(func, *args, **kwargs):
    def run_with_new_loop():
        new_loop = asyncio.new_event_loop()
        asyncio.set_event_loop(new_loop)
        try:
            return func(*args, **kwargs)
        finally:
            new_loop.close()

    import concurrent.futures
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(run_with_new_loop)
        return future.result()


def ask(question: str) -> str:
    try:
        ensure_rag_ready()
        if _rag_chain is None:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        
        print(f"ğŸ” RAGè³ªå•å‡¦ç†é–‹å§‹: {question}")
        result = _rag_chain(question)
        print(f"âœ… RAGå›ç­”ç”Ÿæˆå®Œäº†: {len(result)} æ–‡å­—")
        return result
    except RuntimeError as e:
        if "event loop" in str(e).lower():
            print(f"âš ï¸ ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã€ä»£æ›¿å®Ÿè¡Œä¸­: {e}")
            return _run_with_event_loop(_rag_chain, question)
        else:
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    except Exception as e:
        print(f"âŒ RAGå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"