import os
import asyncio
import threading
import requests
import tempfile
import re
from typing import Optional

from django.conf import settings

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã®è¨­å®š
os.environ["LANGCHAIN_TRACING_V2"] = "false"
os.environ["LANGCHAIN_CALLBACKS_MANAGER"] = "disabled"

from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from langchain.retrievers.multi_query import MultiQueryRetriever


_rag_lock = threading.Lock()
_rag_ready = False
_rag_chain = None


def _extract_google_drive_file_id(url: str) -> Optional[str]:
    """Google Driveã®URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æŠ½å‡º"""
    patterns = [
        r'/file/d/([a-zA-Z0-9-_]+)',
        r'/d/([a-zA-Z0-9-_]+)',
        r'id=([a-zA-Z0-9-_]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None


def _download_from_google_drive(file_id: str, local_path: str) -> bool:
    """Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        print(f"ğŸ“¥ Google Driveã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {file_id}")
        
        # Google Driveã®ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL
        download_url = f"https://drive.google.com/uc?export=download&id={file_id}"
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦Cookieã‚’ç®¡ç†
        session = requests.Session()
        
        # æœ€åˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§Cookieã‚’å–å¾—
        response = session.get(download_url, stream=True)
        response.raise_for_status()
        
        # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã®ç¢ºèªãƒšãƒ¼ã‚¸ã‚’å‡¦ç†
        if 'confirm=' in response.url:
            confirm_token = re.search(r'confirm=([^&]+)', response.url).group(1)
            download_url = f"https://drive.google.com/uc?export=download&confirm={confirm_token}&id={file_id}"
            response = session.get(download_url, stream=True)
            response.raise_for_status()
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        with open(local_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        
        print(f"âœ… Google Driveã‹ã‚‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_path}")
        return True
        
    except Exception as e:
        print(f"âŒ Google Driveã‹ã‚‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        return False


def _download_vectorstore_from_url(url: str, local_path: str) -> bool:
    """å¤–éƒ¨URLã‹ã‚‰ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        print(f"ğŸ“¥ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {url}")
        
        # Google Driveã®URLã‹ãƒã‚§ãƒƒã‚¯
        if 'drive.google.com' in url:
            file_id = _extract_google_drive_file_id(url)
            if file_id:
                return _download_from_google_drive(file_id, local_path)
            else:
                print("âŒ Google Driveã®URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return False
        
        # é€šå¸¸ã®HTTPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        
        with open(local_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print(f"âœ… ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_path}")
        return True
    except Exception as e:
        print(f"âŒ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        return False


def _default_vector_store_path() -> str:
    # RAG_test/aozora_faiss_index ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
    base_dir = getattr(settings, "BASE_DIR", os.getcwd())
    return os.getenv(
        "VECTOR_STORE_PATH",
        os.path.join(base_dir, "RAG_test", "aozora_faiss_index"),
    )


def _ensure_vectorstore_exists():
    """ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãŒå­˜åœ¨ã—ãªã„å ´åˆã€å¤–éƒ¨ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    vector_store_path = _default_vector_store_path()
    
    if not os.path.exists(vector_store_path):
        # å¤–éƒ¨URLã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’è©¦è¡Œ
        vectorstore_url = os.getenv("VECTORSTORE_URL")
        if vectorstore_url:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰å±•é–‹
            with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as tmp_file:
                if _download_vectorstore_from_url(vectorstore_url, tmp_file.name):
                    import zipfile
                    with zipfile.ZipFile(tmp_file.name, 'r') as zip_ref:
                        zip_ref.extractall(os.path.dirname(vector_store_path))
                    os.unlink(tmp_file.name)
                    print(f"âœ… ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’å±•é–‹ã—ã¾ã—ãŸ: {vector_store_path}")
                else:
                    print(f"âŒ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            print(f"âš ï¸ VECTORSTORE_URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")


def _build_rag_chain():
    google_api_key = getattr(settings, "GOOGLE_API_KEY", None)
    if not google_api_key:
        raise RuntimeError("GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®å­˜åœ¨ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    _ensure_vectorstore_exists()
    
    vector_store_path = _default_vector_store_path()
    
    print(f"ğŸ” ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‘ã‚¹ç¢ºèª: {vector_store_path}")
    if not os.path.exists(vector_store_path):
        raise FileNotFoundError(f"ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vector_store_path}")

    # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’è¨­å®šï¼ˆåˆæœŸåŒ–æ™‚ã®ã¿ï¼‰
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    # Embeddings ã¨ VectorStore ã‚’åˆæœŸåŒ–
    print("ğŸ“¥ Embeddingsãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=google_api_key
    )
    
    print("ğŸ“‚ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢èª­ã¿è¾¼ã¿ä¸­...")
    vector_store = FAISS.load_local(
        vector_store_path, embeddings, allow_dangerous_deserialization=True
    )

    base_retriever = vector_store.as_retriever(
        search_type="similarity_score_threshold",
        search_kwargs={"k": 16, "score_threshold": 0.1},
    )

    print("ğŸ¤– LLMãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite", 
        google_api_key=google_api_key, 
        temperature=0,
        # ã‚ˆã‚Šå®‰å…¨ãªè¨­å®š
        max_retries=1,
        timeout=60
    )

    prompt_template = (
        """
ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ã€Œå‚è€ƒæƒ…å ±ã€ã‚’ä¸»ã«ç”¨ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè³ªå•ã€ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€æŒ™ã’ã‚‹ä½œå“ã¯ã§ãã‚‹é™ã‚Šå°èª¬ã§ç‹‚è¨€ã‚„èƒ½ã¯é¿ã‘ã‚‹ã‚ˆã†ã«ã—ã€1ã¤ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ä»¥ä¸‹ã«æº–æ‹ ã—ã¦ãã ã•ã„ã€‚
ãŸã ã—ã€å…·ä½“çš„ãªä½œè€…ã‚’æŒ‡å®šã•ã‚Œãªã„å ´åˆã€ä½œå“ãŒèª°ã‚‚ãŒèª­ã‚“ã ã“ã¨ã®ã‚ã‚‹ã‚ˆã†ãªä½œå“ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ã‚’é¿ã‘ã¦ãã ã•ã„ã€‚
å‚è€ƒæƒ…å ±ãŒä¸ååˆ†ãªå ´åˆã¯ã€æ¤œç´¢ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æƒ…å ±ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒé’ç©ºæ–‡åº«ã®ä¸­ã‹ã‚‰å…·ä½“çš„ãªä½œå“æƒ…å ±ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚å›ç­”ã¯ç°¡æ½”ã«ã€å¯èƒ½ãªã‚‰ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚æœ€å¾Œã«å‚è€ƒã«ã—ãŸä½œå“åï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ»ä½œè€…ï¼‰ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚


ã€å‚è€ƒæƒ…å ±ã€‘
{context}

ã€è³ªå•ã€‘
{question}

ã€å›ç­”ã€‘
"""
    )
    prompt = ChatPromptTemplate.from_template(prompt_template)

    # ã‚·ãƒ³ãƒ—ãƒ«ãªRetrieverã‚’ä½¿ç”¨ï¼ˆMultiQueryRetrieverã¯ä¸€æ—¦ç„¡åŠ¹åŒ–ï¼‰
    print("ğŸ” Retrieverè¨­å®šå®Œäº†")

    def format_docs(docs):
        lines = []
        for i, d in enumerate(docs, 1):
            md = getattr(d, "metadata", {}) or {}
            title = md.get("title", "ä¸æ˜")
            author = md.get("author", "ä¸æ˜")
            source = md.get("source", "")
            lines.append(
                f"[{i}] ã‚¿ã‚¤ãƒˆãƒ«: {title}ï¼ˆ{author}ï¼‰\nå‡ºå…¸: {source}\næœ¬æ–‡æŠœç²‹:\n{getattr(d, 'page_content', '')}"
            )
        return "\n\n---\n\n".join(lines)

    def filter_docs(docs):
        filtered = []
        for d in docs:
            text = (getattr(d, "page_content", "") or "").strip()
            if len(text) < 60:
                continue
            if sum(ch.isdigit() for ch in text) > max(1, int(len(text) * 0.4)):
                continue
            filtered.append(d)
        return filtered or docs

    QUERY_KEYWORDS = [
        "æ˜¥", "æ˜¥é¢¨", "æ˜¥é›¨", "æ˜¥å®µ", "æœ§æœˆå¤œ", "è‹¥è‘‰", "æ–°ç·‘", "èŠ±è¦‹", "æ¡œ", "æ¢…", "èœã®èŠ±", "ã¤ã¤ã˜", "è—¤", "ã†ãã„ã™",
        "å¤", "çœŸå¤", "ç››å¤", "å¤è‡³", "å¤•æš®ã‚Œ", "å¤•æ–¹", "é»„æ˜", "å¤•ç„¼ã‘", "å¤•ç«‹", "ç´æ¶¼", "æ‰“ã¡æ°´", "æš‘æ°—æ‰•ã„",
        "è‰", "ã›ã¿", "è›", "ã»ãŸã‚‹", "é‡‘é­š", "å…¥é“é›²", "æœé¡”", "å‘æ—¥è‘µ", "ã²ã¾ã‚ã‚Š", "ãƒ©ãƒ ãƒ", "æ°·æ°´",
        "æµ·", "æ¸š", "ç ‚æµœ", "æ½®é¢¨", "æµœè¾º", "ç¸æ—¥", "ç¥­", "æµ´è¡£", "å›£æ‰‡", "ã†ã¡ã‚", "æ‰‡å­", "èŠ±ç«", "ç›†", "ç›†è¸Šã‚Š",
        "ç§‹", "ç§‹é›¨", "ç§‹é¢¨", "é‡åˆ†", "å¤œé•·", "å½¼å²¸", "å½¼å²¸èŠ±", "æ›¼ç æ²™è¯", "æœˆ", "åæœˆ", "ä¸­ç§‹", "æœˆè¦‹",
        "ç´…è‘‰", "é»„è‘‰", "ç¨²ç©‚", "æ–°ç±³", "ã™ã™ã", "è™«ã®éŸ³", "éˆ´è™«", "æ¾è™«", "ãã‚Šãã‚Šã™", "éŠ€æ",
        "å†¬", "çœŸå†¬", "æœ¨æ¯ã—", "åŒ—é¢¨", "éœœ", "éœœå¤œ", "é›ª", "ç²‰é›ª", "åˆé›ª", "å¹é›ª", "æ°·", "å‡ã¦ã¤ã",
        "ç‚¬ç‡µ", "ã“ãŸã¤", "ç«é‰¢", "ç‚­ç«", "å›²ç‚‰è£", "ã¿ã‹ã‚“", "é›ªæ˜ã‚Š", "å¸«èµ°", "å¹´ã®ç€¬",
        "é›¨", "å°é›¨", "é©Ÿé›¨", "ã«ã‚ã‹é›¨", "éœ§", "éœ", "é›²", "æ›‡", "å¿«æ™´", "æ™´å¤©", "é›·", "ç¨²å¦»", "è™¹",
        "é¢¨", "æ¶¼é¢¨", "å¯’é¢¨", "å—é¢¨", "åŒ—é¢¨",
        "æœ", "æœç„¼ã‘", "æ˜¼", "æ­£åˆ", "å¤•", "é€¢é­”ãŒæ™‚", "å®µ", "å®µé—‡", "å¤œ", "çœŸå¤œä¸­", "å¤œæ˜ã‘", "æš", "æ˜ã‘æ–¹",
    ]

    def extract_query_terms(question: str) -> set:
        terms = set()
        if not question:
            return terms
        for w in QUERY_KEYWORDS:
            if w in question:
                terms.add(w)
        return terms

    def rerank_docs(docs, question: str, top_n: int = 10):
        docs = filter_docs(docs)
        terms = extract_query_terms(question)
        if not terms:
            return docs[:top_n]

        filtered_by_terms = []
        for d in docs:
            text = getattr(d, "page_content", "")
            md = getattr(d, "metadata", {}) or {}
            kw = md.get("keywords") or {}
            hit = any(t in text for t in terms)
            if not hit and isinstance(kw, dict):
                for arr in kw.values():
                    if any(t in arr for t in terms):
                        hit = True
                        break
            if hit:
                filtered_by_terms.append(d)
        if filtered_by_terms:
            docs = filtered_by_terms

        def score(d):
            text = getattr(d, "page_content", "")
            s = 0
            for t in terms:
                s += text.count(t) * 2
            md = getattr(d, "metadata", {}) or {}
            kw = md.get("keywords") or {}
            if isinstance(kw, dict):
                for arr in kw.values():
                    for t in terms:
                        if t in arr:
                            s += 3
            return s

        ranked = sorted(docs, key=score, reverse=True)
        return ranked[:top_n]

    print("âš™ï¸ RAGãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰ä¸­...")
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªRAGãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰
    def rag_pipeline(question):
        # åŸºæœ¬çš„ãªæ¤œç´¢ï¼ˆæ–°ã—ã„APIã‚’ä½¿ç”¨ï¼‰
        docs = base_retriever.invoke(question)
        # å†ãƒ©ãƒ³ã‚¯ä»˜ã‘
        filtered_docs = rerank_docs(docs, question)
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        context = format_docs(filtered_docs)
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        messages = prompt.format_messages(context=context, question=question)
        # LLMã§å›ç­”ç”Ÿæˆï¼ˆæ–°ã—ã„APIã‚’ä½¿ç”¨ï¼‰
        response = llm.invoke(messages)
        return response.content

    print("âœ… RAGãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰å®Œäº†")
    return rag_pipeline


def ensure_rag_ready():
    global _rag_ready, _rag_chain
    if _rag_ready and _rag_chain is not None:
        return
    with _rag_lock:
        if not _rag_ready:
            print("ğŸš€ RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹...")
            try:
                _rag_chain = _build_rag_chain()
                _rag_ready = True
                print("âœ… RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                print(f"âŒ RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
                raise


def _run_with_event_loop(func, *args, **kwargs):
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦RAGãƒã‚§ãƒ¼ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹"""
    try:
        # æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ—ãŒå®Ÿè¡Œä¸­ã®å ´åˆã€æ–°ã—ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(_run_in_new_thread, func, *args, **kwargs)
                return future.result()
        else:
            # ãƒ«ãƒ¼ãƒ—ãŒåœæ­¢ã—ã¦ã„ã‚‹å ´åˆã€ãã®ã¾ã¾å®Ÿè¡Œ
            return func(*args, **kwargs)
    except RuntimeError:
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã€æ–°ã—ãä½œæˆ
        return _run_in_new_thread(func, *args, **kwargs)

def _run_in_new_thread(func, *args, **kwargs):
    """æ–°ã—ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦å®Ÿè¡Œ"""
    def run_with_new_loop():
        # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
        new_loop = asyncio.new_event_loop()
        asyncio.set_event_loop(new_loop)
        try:
            return func(*args, **kwargs)
        finally:
            new_loop.close()
    
    import concurrent.futures
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(run_with_new_loop)
        return future.result()

def ask(question: str) -> str:
    """RAGã§è³ªå•ã«å›ç­”ã™ã‚‹ã€‚æº–å‚™ãŒæœªå®Œãªã‚‰åˆæœŸåŒ–ã—ã¦ã‹ã‚‰å®Ÿè¡Œã€‚"""
    ensure_rag_ready()
    
    try:
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        print(f"ğŸ” RAGè³ªå•å‡¦ç†é–‹å§‹: {question}")
        result = _rag_chain(question)
        print(f"âœ… RAGå›ç­”ç”Ÿæˆå®Œäº†: {len(result)} æ–‡å­—")
        return result
    except RuntimeError as e:
        if "event loop" in str(e).lower():
            # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€å°‚ç”¨å‡¦ç†ã§å®Ÿè¡Œ
            print(f"âš ï¸ ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã€ä»£æ›¿å®Ÿè¡Œä¸­: {e}")
            return _run_with_event_loop(_rag_chain, question)
        else:
            # ãã®ä»–ã®RuntimeErrorã¯å†ç™ºç”Ÿ
            raise


